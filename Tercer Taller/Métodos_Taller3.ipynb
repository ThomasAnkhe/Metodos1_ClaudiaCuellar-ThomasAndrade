{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # **Métodos Computacionales I - Taller #3**\n",
    "\n",
    "**Hecho por:** Claudia Alejandra Cuellar Nieto & Thomas Andrade Hernández\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zona de librerías:\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as anim\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from matplotlib import rc\n",
    "import sympy as sym\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "import os.path as path\n",
    "import os\n",
    "import wget"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # **5. ÁLGEBRA LINEAL**\n",
    "\n",
    "**$3)\\verb| (Python)|$** Implemente un algoritmo que realice la multiplicación de dos matrices. Use el algoritmo para calcular:\n",
    "\n",
    "$$\n",
    "\\mathbb{AB}\n",
    "\n",
    "=\n",
    "\n",
    "\\begin{pmatrix}\n",
    "    1 & 0 & 0\\\\\n",
    "    5 & 1 & 0\\\\\n",
    "    -2 & 3 & 1\n",
    "\\end{pmatrix}\n",
    "\n",
    "\\cdot \n",
    "\n",
    "\\begin{pmatrix}\n",
    "    4 & -2 & 1\\\\\n",
    "    0 & 3 & 7\\\\\n",
    "    0 & 0 & 2\n",
    "\\end{pmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$4)\\verb| (Theoretical)|$** Muestre con detalle que la sustitución hacia adelante se expresa como:\n",
    "\n",
    "$$x_{i} = b_{i} - \\sum_{j = 0}^{i - 1} A_{ij} \\cdot x_{j}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$5) \\verb| (Theoretical)|$** Muestre con detaller que la sustitución hacia atrás se expresa como:\n",
    "\n",
    "$$x_{i} = \\frac{b_{i} - \\sum_{j = i + 1}^{n} A_{ij} \\cdot x_{j}}{A_{ii}}$$\n",
    "\n",
    "donde $i = n, n - 1, ..., 0$. Note que la diagonal de la matriz triangular puede tener cualquier valor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$6) \\verb| Successive over-relaxation (SOR)|$**. El método de sobre relajación sucesiva se basa en los métodos de Jacobi y Gauss-Seidel, pero incluye un parámetro de escala que reduce el error de aproximación en el paso $(k)$. La formula iterativa está dada por:\n",
    "\n",
    "$$x_{i}^{(k)} = (1 - \\omega) \\cdot x_{i}^{(k - 1)} + \\frac{\\omega}{a_{ii}} \\cdot \\left[ b_{i} - \\sum_{j = 1}^{i - 1} a_{ij}x_{j}^{(k)} -  \\sum_{j = 1}^{i - 1} a_{ij}x_{j}^{(k - 1)}\\right]$$\n",
    "\n",
    "donde $i$ se refiere a la componente del vector, el índice $k$ al paso de la iteración y $0 < \\omega < 2$ es parámetro de relajación. Implemente este método para solucionar el sistema de ecuaciones de clase $(5.4)$ y encuentre el parámetro de relajación que minimiza el número de iteraciones para resolverlo. Cuando $1 < \\omega < 2$ el método se denomina SOR.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$7)\\verb| (Python)|$** Implemente la descomposición $LU$ para factorizar la siguiente matriz $\\mathbb{A} = LU$:\n",
    "\n",
    "$$\n",
    "\\mathbb{A}\n",
    "\n",
    "=\n",
    "\n",
    "\\begin{pmatrix}\n",
    "    4 & -2 & 1\\\\\n",
    "    20 & -7 & 12\\\\\n",
    "    -8 & 13 & 17\n",
    "\\end{pmatrix}\n",
    "\n",
    "=\n",
    "\n",
    "\\begin{pmatrix}\n",
    "    1 & 0 & 0\\\\\n",
    "    5 & 1 & 0\\\\\n",
    "    -2 & 3 & 1\n",
    "\\end{pmatrix}\n",
    "\\cdot\n",
    "\\begin{pmatrix}\n",
    "    4 & -2 & 1\\\\\n",
    "    0 & 3 & 7\\\\\n",
    "    0 & 0 & -2\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$9)\\verb| Método de Jacobi: Diagonalización de matrices simétricas.|$** Cuando la matriz es simétrica $a_{ij}= a_{ji}$, es posible encontrar todos los valores y vectores propios mediante la transformación de la matriz $\\mathbb{A}$ usando matrices de rotación. En particular, una rotación alrededor del eje $z$ está dada por:\n",
    "\n",
    "$$R(\\theta) = \n",
    "\\begin{pmatrix}\n",
    "\\cos\\theta & -\\sin\\theta & 0\\\\\n",
    "\\sin\\theta & \\cos\\theta & 0\\\\\n",
    "0 & 0 & 1\n",
    "\\end{pmatrix}$$\n",
    "\n",
    "donde $i, j$ es la posición del elemento más grande fuera de la diagonal. Investigue en la literatura el algoritmo de Jacobi para diagonalizar matrices simétricas.\n",
    "\n",
    "$(a)$ Implemente el método de Jacobi para encontrar los valores propios de:\n",
    "\n",
    "$$ \\mathbb{A} = \n",
    "\\begin{pmatrix}\n",
    "4 & 1 & 1\\\\\n",
    "1 & 3 & 2\\\\\n",
    "1 & 2 & 5\n",
    "\\end{pmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(b)$ Compare con el resultado que se obtiene de Numpy: $\\verb|np.align.eig(A)|$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$10)\\verb| Quantum system - ground state.|$** Un sistema cuántico de tres niveles está descrito por el siguiente Hamiltoniano:\n",
    "\n",
    "$$\\hat{H} = \n",
    "\\begin{pmatrix}\n",
    "1 & 2 & -1\\\\\n",
    "1 & 0 & 1\\\\\n",
    "4 & -4 & 5\n",
    "\\end{pmatrix}$$\n",
    "\n",
    "Implemente el algoritmo de la potencia inversa para encontrar el valor del estado base $E_0$ y su vector propio $\\lvert \\varphi_{0} \\rangle$. **Ans.** $E_{0} = 1$ y $\\lvert \\varphi_{0} \\rangle = [0.40824829, −0.40824829, −0.81649658]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$12)\\verb| Jacobiano de cuarto orden.|$** Usando el operador derivada central de orden $\\mathfrak{O}(h^4)$ es posible mejorar la estimación del Jacobiano para funciones vectoriales.\n",
    "\n",
    "$(a)$ Escriba una función que estime el Jacobiano con el operador derivada de orden $\\mathfrak{O}(h^4)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(b)$ Estime el Jacobiano de la siguiente función en el punto $x = (0.5, 0.5, 0.5)$ con $h = 0.01$:\n",
    "\n",
    "$$6x_{1} - 2\\cos(x_{2}x_{3}) - 1 = 0$$\n",
    "$$9x_{2} + \\sqrt{x_{1}^2 + \\sin(x_{3}) +1.06} + 0.9 = 0$$\n",
    "$$60x_{3} + 3e^{-x_{1}x_{2}} + 10\\pi - 3 = 0$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(c)$ Estime el Jacobiano usando la aproximación de orden $\\mathfrak{O}(h^2)$ con $h = 0.01$. Para qué valor de $h$, el operador de segundo orden igualará en precisión al operador de cuarto orden; verifique su intuición en el código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # **8.1. MÍNIMOS CUADRADOS**\n",
    "\n",
    "**$1)\\verb| (Python)|$** Se tienen tres líneas en $\\mathbb{R}^2$:\n",
    "\n",
    "$$2x - y = 2$$\n",
    "$$x + 2y = 1$$\n",
    "$$x + y = 4$$\n",
    "\n",
    "$(a)$ Con el método de mínimos cuadrados encuentre el punto común a las tres líneas. Grafique las tres líneas y el punto solución. ¿Qué interpretación puede dar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(b)$ Realice una búsqueda iterativa entre $-5 \\leq x \\leq 5$ y $-5 \\leq y \\leq 5$ con un paso de $h = 0.01$ para encontrar la menor distancia del problema. Grafique la distancia y compare con el resultado obtenido en los mínimos cuadrados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$2)\\verb| (Python)|$** Descargue los datos: https://github.com/asegura4488/Database/blob/main/MetodosComputacionalesReforma/MinimosCuadratico.txt. Realice el ajuste usando el método de mínimos cuadrados para encontrar los parámetros de:\n",
    "\n",
    "$$f(x) = a_{0} + a_{1}x + a_{1}x^2$$\n",
    "\n",
    "Grafique los datos y el ajuste mostrando el valor de las constantes en la etiqueta de la gráfica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$6)\\verb| (Python)|$** En el caso de ajustes, es posible definir funciones de costo que midan la distancia entre los puntos muestrales y el modelo de ajuste. En el caso de mínimos cuadrados la función es $\\mathfrak{X}^2$. Para $n$ puntos y un modelo lineal la función de costo es:\n",
    "\n",
    "$$\\mathfrak{X}^2(a_{0}, a_{1}) = \\sum_{i = 1}^{n} (y_{i} - (a_{0} + a_{1}x_{i}))^2$$\n",
    "\n",
    "Si hablamos en términos Bayesianos, $\\omega = \\{a_{0}, a_{1} \\}$ define el conjunto de modelos lineales que pueden explicar $n$ puntos muestrales. Al minimizar $\\mathfrak{X}^2(a_{0}, a_{1})$ muestre (analíticamente) que los parámetros están dados por:\n",
    "\n",
    "$$a_{0} = \\bar{y} - a_{1}\\bar{x}$$\n",
    "$$a_{1} = \\frac{\\sum xy - \\dfrac{\\sum x \\sum y}{n}}{\\sum x^2 - \\dfrac{(\\sum x)^2}{n}}$$\n",
    "\n",
    "donde $\\bar{x}$ y $\\bar{y}$ son los valores medios de puntos y sus imágenes. Para $n$ puntos y un modelo cuadrático la función de costo es:\n",
    "\n",
    "$$\\mathfrak{X}^2(a_{0}, a_{1}, a_{2}) = \\sum_{i = 1}^{n} (y_{i} - (a_{0} + a_{1}x_{i} + a_{2}x_{i}^2))^2$$\n",
    "\n",
    "Minimize $\\mathfrak{X}^2(a_{0}, a_{1}, a_{2})$ para encontrar el siguiente sistema de ecuaciones. *¿Nota alguna regularidad?*\n",
    "\n",
    "$$\\sum_{i = 1}^{n} \\left[a_{0} + a_{1}x_{i} + a_{2}x_{i}^{2}  = y_{i} \\right]$$\n",
    "$$\\sum_{i = 1}^{n} \\left[a_{0}x_{i} + a_{1}x_{i}^{2} + a_{2}x_{i}^{3}  = x_{i}y_{i} \\right]$$\n",
    "$$\\sum_{i = 1}^{n} \\left[a_{0}x_{i}^{2} + a_{1}x_{i}^{3} + a_{2}x_{i}^{4}  = x_{i}^{2}y_{i} \\right]$$\n",
    "\n",
    "**Opcionalmente:** Encuentre los parámetros usando estas expresiones para los problemas $2)$ y $3)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$7)\\verb| Machine Learning: Logistic Regresion.|$** Descargue los datos de: https://raw.githubusercontent.com/asegura4488/Database/main/MetodosComputacionalesReforma/Sigmoid.csv\n",
    "\n",
    "$(a)$ Defina el modelo de ajuste como:\n",
    "\n",
    "$$M(x;\\vec{\\theta}) = \\frac{\\theta_{0}}{\\theta_{1} + e^{-\\theta_{2}x}}$$\n",
    "\n",
    "donde el $\\vec{\\theta}$ es el vector de parámetros del ajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(b)$ Defina la métrica (función de costo) a minimizar como:\n",
    "\n",
    "$$\\mathfrak{X}^2(\\vec{\\theta}) = \\sum_{i = 1}^{N} \\left( \\frac{y_{i} - M(x_{i}, \\vec{\\theta})}{\\sigma_{i}} \\right)^2$$\n",
    "\n",
    "donde $\\sigma_{i} = 1 \\forall i$, es decir, no se consideran los errores de $y_{i}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(c)$ Muestre que las derivadas parciales de la métrica están dadas por:\n",
    "\n",
    "$$\\frac{\\partial\\mathfrak{X}^2(\\vec{\\theta})}{\\partial\\theta_{i}} = -2 \\cdot \\sum_{i = 1}^{N}(y_{i} - M(x_{i}, \\vec{\\theta})) \\cdot \\frac{\\partial M(x_{i}, \\vec{\\theta})}{\\partial{\\theta_{i}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(d)$ Muestre que vectorialmente, el descenso del gradiente queda definido por:\n",
    "\n",
    "$$\\vec{\\theta}_{j + 1} = \\vec{\\theta}_{j} - \\gamma \\cdot \\left( -2 \\cdot \\sum_{i = 1}^{N}(y_{i} - M(x_{i}, \\vec{\\theta}_{j})) \\cdot \\nabla_{\\theta} M(x_{i}, \\vec{\\theta}_{j}) \\right)$$\n",
    "\n",
    "donde el gradiente es respecto a los parámetros:\n",
    "\n",
    "$$\\nabla_{\\theta} M(x_{i}, \\vec{\\theta}_{j}) = \\left[ \\frac{\\partial M(x_{i}, \\vec{\\theta})}{\\partial\\theta_{0}}, \\frac{\\partial M(x_{i}, \\vec{\\theta})}{\\partial\\theta_{1}},\\frac{\\partial M(x_{i}, \\vec{\\theta})}{\\partial\\theta_{2}} \\right]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(e)$ Use una taza de aprendizaje $\\gamma = 1 \\times 10^{-3}$ o $\\gamma = 5 \\times 10^{-4}$, $\\vec{\\theta}_{0} = [1, 1, 1]$, un error de parada $\\epsilon = 0.01$ y un máximo de iteraciones de $1 \\times 10^{4}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(f)$ Grafique los datos y the best fit model con sus parámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
